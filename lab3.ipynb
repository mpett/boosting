{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Bayes Classifier and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebooks\n",
    "\n",
    "In this lab, you can use Jupyter <https://jupyter.org/> to get a nice layout of your code and plots in one document. However, you may also use Python as usual, without Jupyter.\n",
    "\n",
    "If you have Python and pip, you can install Jupyter with `sudo pip install jupyter`. Otherwise you can follow the instruction on <http://jupyter.readthedocs.org/en/latest/install.html>.\n",
    "\n",
    "And that is everything you need! Now use a terminal to go into the folder with the provided lab files. Then run `jupyter notebook` to start a session in that folder. Click `lab3.ipynb` in the browser window that appeared to start this very notebook. You should click on the cells in order and either press `ctrl+enter` or `run cell` in the toolbar above to evaluate all the expressions.\n",
    "\n",
    "Be sure to put `%matplotlib inline` at the top of every code cell where you call plotting functions to get the resulting plots inside the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "In Jupyter, select the cell below and press `ctrl + enter` to import the needed libraries.\n",
    "Check out `labfuns.py` if you are interested in the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "from imp import reload\n",
    "from labfuns import *\n",
    "from sklearn import decomposition\n",
    "from matplotlib.colors import ColorConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes classifier functions to implement\n",
    "\n",
    "The lab descriptions state what each function should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that you do not need to handle the W argument for this part\n",
    "# in: labels - N x 1 vector of class labels\n",
    "# out: prior - C x 1 vector of class priors\n",
    "def computePrior(labels,W=None):\n",
    "    # Your code here\n",
    "    return prior\n",
    "\n",
    "# Note that you do not need to handle the W argument for this part\n",
    "# in:      X - N x d matrix of N data points\n",
    "#     labels - N x 1 vector of class labels\n",
    "# out:    mu - C x d matrix of class means\n",
    "#      sigma - d x d x C matrix of class covariances\n",
    "def mlParams(X,labels,W=None):\n",
    "    # Your code here\n",
    "    return mu, sigma\n",
    "\n",
    "# in:      X - N x d matrix of M data points\n",
    "#      prior - C x 1 vector of class priors\n",
    "#         mu - C x d matrix of class means\n",
    "#      sigma - d x d x C matrix of class covariances\n",
    "# out:     h - N x 1 class predictions for test points\n",
    "def classify(X,prior,mu,sigma,covdiag=True):\n",
    "    # Your code here\n",
    "    # Example code for solving a psd system\n",
    "    # L = np.linalg.cholesky(A)\n",
    "    # y = np.linalg.solve(L,b)\n",
    "    # x = np.linalg.solve(L.H,y)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Maximum Likelihood estimates\n",
    "\n",
    "Call `genBlobs` and `plotGaussian` to verify your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "X, labels = genBlobs(centers=5)\n",
    "mu, sigma = mlParams(X,labels)\n",
    "plotGaussian(X,labels,mu,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting functions to implement\n",
    "\n",
    "The lab descriptions state what each function should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in:       X - N x d matrix of N data points\n",
    "#      labels - N x 1 vector of class labels\n",
    "#           T - number of boosting iterations\n",
    "# out: priors - length T list of prior as above\n",
    "#         mus - length T list of mu as above\n",
    "#      sigmas - length T list of sigma as above\n",
    "#      alphas - T x 1 vector of vote weights \n",
    "def trainBoost(X,labels,T=5,covdiag=True):\n",
    "    # Your code here\n",
    "    return priors,mus,sigmas,alphas\n",
    "\n",
    "# in:       X - N x d matrix of N data points\n",
    "#      priors - length T list of prior as above\n",
    "#         mus - length T list of mu as above\n",
    "#      sigmas - length T list of sigma as above\n",
    "#      alphas - T x 1 vector of vote weights\n",
    "# out:  yPred - N x 1 class predictions for test points\n",
    "def classifyBoost(X,priors,mus,sigmas,alphas,covdiag=True):\n",
    "    # Your code here\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our testing function\n",
    "\n",
    "The function below, `testClassifier`, will be used to try out the different datasets. `fetchDataset` can be provided with any of the dataset arguments `wine`, `iris`, `olivetti` and `vowel`. Observe that we split the data into a **training** and a **testing** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=25)\n",
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "def testClassifier(dataset='iris',dim=0,split=0.7,doboost=False,boostiter=5,covdiag=True,ntrials=100):\n",
    "\n",
    "    X,y,pcadim = fetchDataset(dataset)\n",
    "\n",
    "    means = np.zeros(ntrials,);\n",
    "\n",
    "    for trial in range(ntrials):\n",
    "\n",
    "        # xTr,yTr,xTe,yTe,trIdx,teIdx = trteSplit(X,y,split)\n",
    "        xTr,yTr,xTe,yTe,trIdx,teIdx = trteSplitEven(X,y,split)\n",
    "\n",
    "        # Do PCA replace default value if user provides it \n",
    "        if dim > 0:\n",
    "            pcadim = dim\n",
    "        if pcadim > 0:     \n",
    "            pca = decomposition.PCA(n_components=pcadim)\n",
    "            pca.fit(xTr)\n",
    "            xTr = pca.transform(xTr)\n",
    "            xTe = pca.transform(xTe)     \n",
    "\n",
    "        ## Boosting  \n",
    "        if doboost:\n",
    "            # Compute params\n",
    "            priors,mus,sigmas,alphas = trainBoost(xTr,yTr,T=boostiter,covdiag=covdiag)\n",
    "            yPr = classifyBoost(xTe,priors,mus,sigmas,alphas)        \n",
    "        else:\n",
    "        ## Simple\n",
    "            # Compute params\n",
    "            prior = computePrior(yTr)\n",
    "            mu, sigma = mlParams(xTr,yTr)\n",
    "            # Predict\n",
    "            yPr = classify(xTe,prior,mu,sigma,covdiag=covdiag)\n",
    "\n",
    "        # Compute classification error\n",
    "        print \"Trial:\",trial,\"Accuracy\",100*np.mean((yPr==yTe).astype(float))\n",
    "\n",
    "        means[trial] = 100*np.mean((yPr==yTe).astype(float))\n",
    "\n",
    "    print \"Final mean classification accuracy \", np.mean(means), \"with standard deviation\", np.std(means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the decision boundary\n",
    "\n",
    "This is some code that you can use for plotting the decision boundary\n",
    "boundary in the last part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotBoundary(dataset='iris',split=0.7,doboost=False,boostiter=5,covdiag=True):\n",
    "    \n",
    "    X,y,pcadim = fetchDataset(dataset)\n",
    "    xTr,yTr,xTe,yTe,trIdx,teIdx = trteSplitEven(X,y,split)\n",
    "    pca = decomposition.PCA(n_components=2)\n",
    "    pca.fit(xTr)\n",
    "    xTr = pca.transform(xTr)\n",
    "    xTe = pca.transform(xTe)\n",
    "    \n",
    "    pX = np.vstack((xTr, xTe))\n",
    "    py = np.hstack((yTr, yTe))\n",
    "     \n",
    "    if doboost:\n",
    "        ## Boosting\n",
    "        # Compute params\n",
    "        priors,mus,sigmas,alphas = trainBoost(xTr,yTr,T=boostiter,covdiag=covdiag)       \n",
    "    else:\n",
    "        ## Simple\n",
    "        # Compute params\n",
    "        prior = computePrior(yTr)\n",
    "        mu, sigma = mlParams(xTr,yTr)\n",
    "\n",
    "    xRange = np.arange(np.min(pX[:,0]),np.max(pX[:,0]),np.abs(np.max(pX[:,0])-np.min(pX[:,0]))/100.0)\n",
    "    yRange = np.arange(np.min(pX[:,1]),np.max(pX[:,1]),np.abs(np.max(pX[:,1])-np.min(pX[:,1]))/100.0)\n",
    "\n",
    "    grid = np.zeros((yRange.size, xRange.size))\n",
    "    \n",
    "    for (xi, xx) in enumerate(xRange):\n",
    "        for (yi, yy) in enumerate(yRange):\n",
    "            if doboost:\n",
    "                ## Boosting \n",
    "                grid[yi,xi] = classifyBoost(np.matrix([[xx, yy]]),priors,mus,sigmas,alphas,covdiag=covdiag)        \n",
    "            else:\n",
    "                ## Simple\n",
    "                grid[yi,xi] = classify(np.matrix([[xx, yy]]),prior,mu,sigma,covdiag=covdiag)\n",
    "    \n",
    "    classes = range(np.min(y), np.max(y)+1)\n",
    "    ys = [i+xx+(i*xx)**2 for i in range(len(classes))]\n",
    "    colormap = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "\n",
    "    plt.hold(True)\n",
    "    conv = ColorConverter()\n",
    "    for (color, c) in zip(colormap, classes):\n",
    "        try:\n",
    "            CS = plt.contour(xRange,yRange,(grid==c).astype(float),15,linewidths=0.25,colors=conv.to_rgba_array(color))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        xc = pX[py == c, :]\n",
    "        plt.scatter(xc[:,0],xc[:,1],marker='o',c=color,s=40,alpha=0.5)\n",
    "        \n",
    "    plt.xlim(np.min(pX[:,0]),np.max(pX[:,0]))\n",
    "    plt.ylim(np.min(pX[:,1]),np.max(pX[:,1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some experiments\n",
    "\n",
    "Call the `testClassifier` and `plotBoundary` functions for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Example usage of the functions\n",
    "\n",
    "testClassifier(dataset='iris',split=0.7,doboost=False,boostiter=5,covdiag=True)\n",
    "plotBoundary(dataset='iris',split=0.7,doboost=False,boostiter=5,covdiag=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
